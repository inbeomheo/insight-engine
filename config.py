"""
ìŠ¤ë§ˆíŠ¸ ì½˜í…ì¸  ìƒì„±ê¸° ì„¤ì • íŒŒì¼
AI ì„œë¹„ìŠ¤, ìŠ¤íƒ€ì¼ ì˜µì…˜ ì •ì˜
í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ì€ prompts.pyì—ì„œ ê´€ë¦¬
"""
from typing import Dict, List, Any
import os

# prompts.pyì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
from prompts import STYLE_PROMPTS

# YouTube API Key
YOUTUBE_API_KEY: str = os.getenv('YOUTUBE_API_KEY', '')

# Token Limits (ê¸°ë³¸ê°’, ëª¨ë¸ë³„ ì„¤ì •ì´ ì—†ì„ ë•Œ ì‚¬ìš©)
MAX_TRANSCRIPT_TOKENS: int = 100000
MAX_COMMENTS_TOKENS: int = 5000
MAX_CONTENT_TOKENS: int = 100000  # ê¸°ë³¸ fallback ê°’

# ì§€ì› AI ì„œë¹„ìŠ¤ ì •ì˜ (max_input_tokens: ì»¨í…ìŠ¤íŠ¸ ìœˆë„ìš°ì˜ ~75% í• ë‹¹)
SUPPORTED_PROVIDERS: Dict[str, Dict[str, Any]] = {
    'openai': {
        'name': 'OpenAI',
        'models': [
            {'id': 'gpt-4o', 'name': 'GPT-4o', 'max_input_tokens': 96000},              # 128K context
            {'id': 'gpt-4o-mini', 'name': 'GPT-4o Mini', 'max_input_tokens': 96000},    # 128K context
            {'id': 'gpt-4-turbo', 'name': 'GPT-4 Turbo', 'max_input_tokens': 96000},    # 128K context
            {'id': 'gpt-3.5-turbo', 'name': 'GPT-3.5 Turbo', 'max_input_tokens': 12000} # 16K context
        ],
        'key_placeholder': 'sk-...',
        'key_prefix': 'sk-'
    },
    'anthropic': {
        'name': 'Claude (Anthropic)',
        'models': [
            {'id': 'claude-sonnet-4-20250514', 'name': 'Claude Sonnet 4', 'max_input_tokens': 150000},   # 200K context
            {'id': 'claude-3-5-sonnet-20241022', 'name': 'Claude 3.5 Sonnet', 'max_input_tokens': 150000},
            {'id': 'claude-3-haiku-20240307', 'name': 'Claude 3 Haiku', 'max_input_tokens': 150000}
        ],
        'key_placeholder': 'sk-ant-...',
        'key_prefix': 'sk-ant-'
    },
    'gemini': {
        'name': 'Google Gemini',
        'models': [
            {'id': 'gemini/gemini-3-flash-preview', 'name': 'Gemini 3 Flash (ìµœì‹ )', 'max_input_tokens': 750000},    # 1M context
            {'id': 'gemini/gemini-3-pro-preview', 'name': 'Gemini 3 Pro (ìµœì‹ )', 'max_input_tokens': 750000},
            {'id': 'gemini/gemini-2.5-flash-preview-09-2025', 'name': 'Gemini 2.5 Flash', 'max_input_tokens': 750000},
            {'id': 'gemini/gemini-2.5-flash-lite-preview-09-2025', 'name': 'Gemini 2.5 Flash Lite', 'max_input_tokens': 750000},
            {'id': 'gemini/gemini-2.0-flash', 'name': 'Gemini 2.0 Flash', 'max_input_tokens': 750000},
            {'id': 'gemini/gemini-1.5-pro-latest', 'name': 'Gemini 1.5 Pro', 'max_input_tokens': 1500000}  # 2M context
        ],
        'key_placeholder': 'AIza...',
        'key_prefix': 'AIza'
    },
    'zhipu': {
        'name': 'GLM-4 (Zhipu AI)',
        'models': [
            {'id': 'glm-4', 'name': 'GLM-4', 'max_input_tokens': 96000},           # 128K context
            {'id': 'glm-4-flash', 'name': 'GLM-4 Flash', 'max_input_tokens': 96000},
            {'id': 'glm-4-air', 'name': 'GLM-4 Air', 'max_input_tokens': 96000}
        ],
        'key_placeholder': 'API Key',
        'key_prefix': ''
    },
    'deepseek': {
        'name': 'DeepSeek',
        'models': [
            {'id': 'deepseek/deepseek-chat', 'name': 'DeepSeek-V3 (ì±„íŒ…)', 'max_input_tokens': 96000},    # 128K context
            {'id': 'deepseek/deepseek-reasoner', 'name': 'DeepSeek-R1 (ì¶”ë¡ )', 'max_input_tokens': 96000}
        ],
        'key_placeholder': 'sk-...',
        'key_prefix': 'sk-'
    }
}

# ìŠ¤íƒ€ì¼/í†¤ ì˜µì…˜
STYLE_OPTIONS: List[tuple] = [
    ('blog', 'ğŸ“ ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸'),
    ('detailed', 'ğŸ“ ìƒì„¸ ìš”ì•½'),
    ('summary', 'âš¡ í•µì‹¬ ìš”ì•½'),
    ('easy', 'ğŸ¯ ì‰¬ìš´ ì„¤ëª…'),
    ('news', 'ğŸ“° ë‰´ìŠ¤ ìŠ¤íƒ€ì¼'),
    ('script', 'ğŸ¬ ìŠ¤í¬ë¦½íŠ¸'),
    ('seo', 'ğŸ” SEO ìµœì í™”'),
    ('needs', 'ğŸ’¡ ë‹ˆì¦ˆ/ì•„ì´í…œ ë¶„ì„'),
    ('qna', 'â“ Q&A í˜•ì‹'),
    ('infographic', 'ğŸ“Š ì¸í¬ê·¸ë˜í”½ìš©'),
    ('compare', 'âš–ï¸ ë¹„êµë¶„ì„'),
    ('sns', 'ğŸ“± SNS í¬ìŠ¤íŒ…')
]

# ì„¸ë¶€ ì˜µì…˜ (ê¸¸ì´, í†¤, ì–¸ì–´, ì´ëª¨ì§€)
STYLE_MODIFIERS: Dict[str, Dict[str, str]] = {
    'length': {
        'short': 'ì´ ë¶„ëŸ‰ì€ ì•½ 300ì ë‚´ì™¸ë¡œ í•µì‹¬ë§Œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.',
        'medium': 'ì´ ë¶„ëŸ‰ì€ ì•½ 800ì ë‚´ì™¸ë¡œ ì ì ˆíˆ ì‘ì„±í•˜ì„¸ìš”.',
        'long': 'ì´ ë¶„ëŸ‰ì€ ì•½ 1500ì ì´ìƒìœ¼ë¡œ ìƒì„¸í•˜ê³  í’ë¶€í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.'
    },
    'tone': {
        'professional': 'ë§íˆ¬ëŠ” ì „ë¬¸ì ì´ê³  ê°ê´€ì ì¸ ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. ê²½ì–´ì²´(~ìŠµë‹ˆë‹¤, ~ì…ë‹ˆë‹¤)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.',
        'friendly': 'ë§íˆ¬ëŠ” ì¹œê·¼í•˜ê³  ëŒ€í™”í•˜ë“¯ì´ ì‘ì„±í•˜ì„¸ìš”. ë¶€ë“œëŸ¬ìš´ ì–´ì¡°ë¡œ ë…ìì™€ ì†Œí†µí•˜ëŠ” ëŠë‚Œì„ ì£¼ì„¸ìš”.',
        'humorous': 'ë§íˆ¬ëŠ” ìœ ë¨¸ëŸ¬ìŠ¤í•˜ê³  ì¬ì¹˜ìˆê²Œ ì‘ì„±í•˜ì„¸ìš”. ì ì ˆí•œ ìœ„íŠ¸ì™€ ê°€ë²¼ìš´ ë†ë‹´ì„ í¬í•¨í•˜ì„¸ìš”.'
    },
    'language': {
        'ko': 'ê²°ê³¼ëŠ” ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.',
        'en': 'Please write the result in English.',
        'ja': 'çµæœã¯å¿…ãšæ—¥æœ¬èªã§ä½œæˆã—ã¦ãã ã•ã„ã€‚'
    },
    'emoji': {
        'use': 'ì ì ˆí•œ ì´ëª¨ì§€ë¥¼ í™œìš©í•˜ì—¬ ê°€ë…ì„±ê³¼ ì¬ë¯¸ë¥¼ ë†’ì´ì„¸ìš”. ê° ì„¹ì…˜ì´ë‚˜ ì¤‘ìš” í¬ì¸íŠ¸ì— ì´ëª¨ì§€ë¥¼ ì¶”ê°€í•˜ì„¸ìš”.',
        'none': 'ì´ëª¨ì§€ëŠ” ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”. í…ìŠ¤íŠ¸ë§Œìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”.'
    }
}

# STYLE_PROMPTSëŠ” prompts.pyì—ì„œ importë¨

def get_model_max_tokens(model_id: str) -> int:
    """ëª¨ë¸ IDë¡œ ìµœëŒ€ ì…ë ¥ í† í° ìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    for provider in SUPPORTED_PROVIDERS.values():
        for model in provider.get('models', []):
            if model['id'] == model_id:
                return model.get('max_input_tokens', MAX_CONTENT_TOKENS)
    return MAX_CONTENT_TOKENS  # fallback

__all__ = [
    'YOUTUBE_API_KEY',
    'MAX_TRANSCRIPT_TOKENS',
    'MAX_COMMENTS_TOKENS',
    'MAX_CONTENT_TOKENS',
    'SUPPORTED_PROVIDERS',
    'STYLE_OPTIONS',
    'STYLE_MODIFIERS',
    'STYLE_PROMPTS',
    'get_model_max_tokens'
]
